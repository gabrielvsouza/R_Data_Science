getwd()
setwd("~/HARVARDx/02_Wrangling")
#data wrangling
###https://www.rdocumentation.org/packages/dslabs
#to use as their working director
setwd("/Users/student/Documents/projects/")
#to copy the "murders.csv" file from the dslabs package into an 
#existing folder "data"
library(dslabs)
library(readr)
library(dplyr)
library(ggplot2)
library(stringr)
library(lubridate)
library(tidyr)
library(dslabs)
wd = getwd()
filename = "murders.csv"
path = system.file("extdata", package = "dslabs")
file.copy(file.path(path, "murders.csv"), file.path(getwd(), "data"))

# to know header and 3 firsts lines
read_Lines("murders.csv", n_max =3)

#race_times <- read.csv(“times.csv”)

# download file direct form url
download.file(url, "murders.csv")

# use these commands to download a file,
# give it a temporary name, read it in, and then erase
#tempdir()
#tempfile()
tmp_filename <- tempfile()
download.file(url, tmp_filename)
dat <- read_csv(tmp_filename)
file.remove(tmp_filename)

#Tidy Data
# Reshape data using functions from the tidyr package, including gather, spread, separate, and unite.
#Combine information from different tables using join functions from the dplyr package.
#Combine information from different tables using binding functions from the dplyr package.
#Use set operators to combine data frames.
#Gather data from a website through web scraping and use of CSS selectors.
new_tidy_data <- wide_data %>%
      gather(year, ferility, '1960':'2015')
# or
new_tidy_data <- wide_data %>%
  gather(year, ferility, -country)
# gather assumes column name as character and need to convert to numeric
new_tidy_data <- wide_data %>%
  gather(year, ferility, -country, convert = TRUE)
# spread() to convert tidy data into wide format


# Separate and Unite
# separate
path <- system.file("extdata", package = "dslabs")
filename <- file.path(path, "life-expectancy_and_fertility_two_countries_example.cvs")
raw_dat <- read_csv(filename)
select(raw_dat, 1:5)
#gather
dat <- raw_dat %>% gather(key, value, - country)
head(dat)
#separete
dat$key[1:5]
#Encoding multiple variables in a column name
#is such a common problem
# 1 first attempt
dat %>% separate(key, c("year", "variable_name"), "_")
#warning message
#This is because the underscore is used to separate life
#and expectancy in the name, not just to separate year and the variable name.
#2
dat %>% separate(key, c("year", "first_variable_name", "second_variable_name"),
                 fill = "right")
#However, if we read the separate file, we
#find that a better approach is to merge the last two
#variables when there's an extra separation
#using the argument extra
#3
dat %>% separate(key, c("year", "variable_name"), sep ="_", extra = "merge")
# need to create a column for each variable.
dat %>% separate(key, c("year", "variable_name"), sep ="_", extra = "merge") %>%
  spread(variable_names, value)


# Combining Tables
####
head(murders)
head(polls_us_election_2016)
#Notice that just joining these two tables together like this
#will not work since the order of the states is not quite the same.
identical(results_us_election_2016$state, murders$state)
# note what happens if we join the two tables by state using left join
# data has been successfully joined
tab <- left_join(murders, results_us_election_2016, by = "state")
head(tab)
#plot
library(ggrepel)
tab%>% ggplot(aes(population/10^6, electoral_votes, label = abb)) +
  geom_point() +
  geom_text_repel() +
  scale_x_continuous(trans = "log2") +
  scale_y_continuous(trans = "log2") +
  geom_smooth(method = "lm", se = FALSE, col = "blue")

##### others way to join tables
tab1 <- slice(murders, 1:6) %>% select(state, population)
tab1
# ordenando por estado
# new <- murders2[order(murders2$rate),]
ordd <- results_us_election_2016[order(results_us_election_2016$state),]
head(ordd)
tab2 <- slice(ordd, c(1:3, 5, 7:8)) %>% 
  select(state, electoral_votes)
tab2
#### left join
left_join(tab1, tab2)
tab1 %>% left_join(tab2) 
# NAs 
#rigth_join
tab1 %>% right_join(tab2)
# NA Notice that now the NAs are in the columns coming from tab one.
# to keep only the rows that have information in both tables,
# use inner join.
inner_join(tab1, tab2)
# union whith NA
full_join(tab1, tab2)
###semi join
semi_join(tab1, tab2)
### anti join
anti_join(tab1, tab2)
    

###Binding
# create tibbles
bind_cols(a = 1:3, b = 4:6)
# create objects
cbind()
# bind_cols create new DF
tab3 <- tab2 <- slice(ordd, 1:6) %>% 
  select(state, electoral_votes)
tab3
newdf <- bind_cols(tab1, tab3)
newdf
# binding rows
# bind_rows
tab4 <- tab[1:2,]
tab5 <- tab[3:4,]
bind_rows(tab4, tab5)


##### Set Operators
#intersect()
# ake the intersection of rows for tables having the same column names.
tab4 <- tab[1:5,]
tab4
tab5 <- tab[3:7,]
tab5
intersect(tab4, tab5)
# union
union(tab4, tab5)
# setdiff
# setequal


library(rvest)

url <- "https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state"
h <- read_html(url)
h
class(h)

# to extract the first table, we can use this very simple code
tab <- h %>% html_nodes("table")
tab <- tab[[2]]
tab

# for converting HTML tables into data frames
tab <- tab%>% html_table()
class(tab)
head(tab)
View(tab)
# change columns names
tab1 <- tab %>% setNames(c("state", "population", "total", 
                          "murders", "gun_murders", "gun_ownership",
                          "total_rate", "murder_rate", "gun_murder_rate"))
View(tab1)


### CSS Selectors
#To do this CSS leverages patterns used to define these elements, referred to as selectors. 

h <- read_html("http://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609")
recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
directions <- h %>% html_node(".o-Method__m-Step") %>% html_text()
guacamole <- list(recipe, prep_time, ingredients, directions)
guacamole



get_recipe <- function(url){
  h <- read_html(url)
  recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
  prep_time <- h %>% html_nodes(".o-RecipeInfo__a-Description") %>% html_text()
  ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
  return(list(recipe = recipe, prep_time = prep_time[2], ingredients = ingredients))
}

get_recipe("https://www.foodnetwork.com/recipes/alton-brown/vegetarian-steamed-dumplings-recipe-1942919")



h <- read_html("http://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609")
recipe <- h %>% html_node(".o-Method__m-Step") %>% html_text()
prep_time <- h %>% html_node(".o-RecipeInfo__m-Time") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()

guacamole <- list(recipe, prep_time, ingredients)
guacamole



#### String Processing Overview
#string processing is a powerful tool useful for overcoming many data wrangling challenges
#Remove unwanted characters from text.
#Extract  numeric values from text.
#Find and replace characters.
#Extract  specific parts of strings.
#Convert free form text into more uniform formats.
#Split strings into multiple values.
#Use regular expressions (regex) to process strings.
library(rvest)
library(dplyr)
library(stringr)
library(readr)

url <- "https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state"
murders_raw <- read_html(url) %>% 
  html_nodes("table") %>% 
  html_table()
murders_raw <- murders_raw[[2]] %>% 
  setNames(c("state", "population", "total", 
  "murders", "gun_murders", "gun_ownership",
  "total_rate", "murder_rate", "gun_murder_rate"))
View(murders_raw)
head(murders_raw)
class(murders_raw)
class(murders_raw$population)
class(murders_raw$total)

### Single and Double Quotes and How to Escape
s <- '10"'
cat(s)
# 10"
s <- '5\'10"'
cat(s)
# 5'10"
cat(" LeBron James is 6’8\" ")
# LeBron James is 6’8" 


### stringr Package
murders_raw$population[1:3]
#the usual coercion to convert numbers doesn't work here
# This is because of the commas
as.numeric(murders_raw$population[1:3])
# In general, string processing tasks can be
# divided into detecting, locating, extracting,
# or replacing patterns in strings
#
# we need to locate the comma
# and replace them with an empty character



#Case Study 1: US Murders Data
# use the str_detect() function to see that 
# the columns have commas using this code
commas <- function(x) any(str_detect(x, ","))
murders_raw %>% summarize_all(list(commas))
# use the str_replace_all function
# to remove them using this code
test_1 <-  str_replace_all(murders_raw$population, ",", "")
test_1 <- as.numeric((test_1))
test_1
View(test_1)
# We can then use the mutate_all to apply this operation to each column,
#since it won't affect the columns without commas
#It turns out that this operation is so common
#removing commas that readr includes the function parse_number()
test_2 <- parse_number(murders_raw$population)
test_2
identical(test_1, test_2)
# obtain our desired table using the following code.
murders_new <- murders_raw %>% mutate_at(2:3, parse_number)
murders_new %>% head
View(murders_new)



######## Case Study 2: Reported Heights
library(dslabs)
library(tidyverse)
data(reported_heights)
head(reported_heights)
class(reported_heights$height)
x <- as.numeric(reported_heights$height)
head(x)
# how many NAs
sum(is.na(x))
#We can see some of the entries that are not successfully
#converted by using the filter function to keep only the entries that
#resulted in NAs
reported_heights %>% mutate(new_height = as.numeric(height)) %>%
  filter(is.na(new_height)) %>%
  head(n=10)
#We want to find patterns that can be accurately described
# We only keep entries that either result in NAs when applying as numeric
#We also use suppressWarnings throughout the code
#to avoid the warning messages we know the as.numeric will give us.
not_inches <- function(x, smallest = 50, tallest = 84){
  inches <- suppressWarnings(as.numeric(x))
  ind <- is.na(inches) | inches < smallest | inches > tallest
  ind
}
#We apply this function and find the number of problematic entries
problems <- reported_heights %>% 
  filter(not_inches(height)) %>%
  pull(height)
length(problems)
#We can now view all the cases by simply printing them
View(problems)
#but after surveying them carefully, we see that three patterns can be used to define 
#three large groups within these exceptions
#1-A pattern of the form x'y or x' y'' or x'y"
#2-pattern of the form x.y or x,y
#3-Entries that were reported in centimeters rather than inches



#### Regex regular expressions (regex)
#A regular expression (regex) is way to describe specific patterns of characters of text
#show all the entries that used cm
str_subset(reported_heights$height, "cm")
# Which of the following strings contain the pattern cm or inche
yes <- c("180 cm", "70 inches")
no <- c("180", "70''")
s <- c(yes, no)
str_detect(s, "cm") | str_detect(s, "inches")
#However, we don’t need to do this
str_detect(s, "cm|inches")
#inches values is \d which means any digit: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
#In R, we have to escape the backslash \ so we actually have to use \\d to represent digit
yes <- c("5", "6", "5'10", "5 feet", "4'11")
no <- c("", ".", "Five", "six")
s <- c(yes, no)
pattern <- "\\d"
str_detect(s, pattern)
####str_view function, which is helpful for troubleshooting as it shows us the first match for each string
#packages("htmlwidgets")
install.packages("htmlwidgets")
str_view(s, pattern)
#str_view_all shows us all the matches
str_view_all(s, pattern)

#Character classes
#used to define a series of characters that can be matched
str_view(s, "[56]")
#Suppose we want to match values between 4 and 7
yes <- as.character(4:7)
no <- as.character(1:3)
s <- c(yes, no)
str_detect(s, "[4-7]")
#> [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE

#Anchors
#What if we want a match when we have exactly 1 digit
pattern <- "^\\d$"
yes <- c("1", "5", "9")
no <- c("12", "123", " 1", "a4", "b")
s <- c(yes, no)
str_view_all(s, pattern)

#Quantifiers
#we can have one or two digits. This can be specified in regex with quantifiers
pattern <- "^\\d{1,2}$"
yes <- c("1", "5", "9", "12")
no <- c("123", "a4", "b")
str_view(c(yes, no), pattern)


pattern <- "^[4-7]'\\d{1,2}\"$"

#Let’s test it out:
yes <- c("5'7\"", "6'2\"",  "5'12\"")
no <- c("6,2\"", "6.2\"","I am 5'11\"", "3'2\"", "64")
str_detect(yes, pattern)
#> [1] TRUE TRUE TRUE
str_detect(no, pattern)

animals <- c("cat", "puppy", "Moose", "MONKEY")
pattern <- "[a-z]{4,5}"
str_detect(animals, pattern)

#Search and Replace with Regex
#strings that do not appear to be in inches
pattern <- "^[4-7]'\\d{1,2}\"$"
sum(str_detect(problems, pattern))
problems[c(2, 10, 11, 12, 15)] %>% str_view(pattern)
#wrote out the words “feet” and “inches”
str_subset(problems, "inches")
str_subset(problems, "''")
#To correct this, we can replace the different ways of representing inches and feet with a uniform symbol
pattern <- "^[4-7]'\\d{1,2}$"
problems %>% 
  str_replace("feet|ft|foot", "'") %>% # replace feet, ft, foot with ' 
  str_replace("inches|in|''|\"", "") %>% # remove all inches symbols
  str_detect(pattern) %>% 
  sum()
#improve our pattern by adding \\s*
pattern <- "^[4-7]\\s*'\\s*\\d{1,2}$"
problems %>% 
  str_replace("feet|ft|foot", "'") %>% # replace feet, ft, foot with ' 
  str_replace("inches|in|''|\"", "") %>% # remove all inches symbols
  str_detect(pattern) %>% 
  sum
#We might be tempted to avoid doing this by removing all the spaces with str_replace_all


#Groups with Regex
#Search and replace using groups
pattern_with_groups <-  "^([4-7]),(\\d*)$"
yes <- c("5,9", "5,11", "6,", "6,1")
no <- c("5'9", ",", "2,8", "6.1.1")
s <- c(yes, no)
str_replace(s, pattern_with_groups, "\\1'\\2")
#We are now ready to define a pattern that helps us convert all the x.y, x,y and x y to our preferred format
pattern_with_groups <-"^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$"
#Let’s break this one down:
#   ^ = start of the string
#   [4-7] = one digit, either 4,5,6 or 7
#   \\s* = none or more white space
#   [,\\.\\s+] = feet symbol is either ,, . or at least one space.
#   \\s* = none or more white space
#   \\d* = none or more digits
#   $ = end of the string
str_subset(problems, pattern_with_groups) %>% head()
str_subset(problems, pattern_with_groups) %>% 
  str_replace(pattern_with_groups, "\\1'\\2") %>% head

#Testing and Improving
not_inches_or_cm <- function(x, smallest = 50, tallest = 84){
  inches <- suppressWarnings(as.numeric(x))
  ind <- !is.na(inches) & 
    ((inches >= smallest & inches <= tallest) |
       (inches/2.54 >= smallest & inches/2.54 <= tallest))
  !ind
}

problems <- reported_heights %>% 
  filter(not_inches_or_cm(height)) %>%
  pull(height)
length(pHarvardX PH125.6x Certificate _ edXroblems)

#proportion of these fit our pattern after the processing steps we developed above
converted <- problems %>% 
  str_replace("feet|foot|ft", "'") %>% # convert feet symbols to '
  str_replace("inches|in|''|\"", "") %>%  # remove inches symbols
  str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2") # change format

pattern <- "^[4-7]\\s*'\\s*\\d{1,2}$"
index <- str_detect(converted, pattern)
mean(index)

# https://rafalab.github.io/dsbook/string-processing.html



#Using Groups and Quantifiers

#Four clear patterns of entries have arisen along with some other minor problems:
  
# - Many students measuring exactly 5 or 6 feet did not enter any inches. 
#   For example, 6' - our pattern requires that inches be included.
# - Some students measuring exactly 5 or 6 feet entered just that number.
# - Some of the inches were entered with decimal points. For example 5'7.5''. 
#   Our pattern only looks for two digits.
# - Some entires have spaces at the end, for example 5 ' 9.
# - Some entries are in meters and some of these use European decimals: 1.6, 1,7.
# - Two students added cm.
# - One student spelled out the numbers: Five foot eight inches.
#It is not necessarily clear that it is worth writing code to handle all 
#these cases since they might be rare enough. However, some give us an opportunity
#to learn some more regex techniques so we will build a fix.

#https://rafalab.github.io/dsbook/string-processing.html
#https://courses.edx.org/courses/course-v1:HarvardX+PH125.6x+1T2019/courseware/c59e9550f970406e81b8a908ce42dcc0/ce005733735d4d3ebfd8eeab3845b19f/?child=first


#Separate with Regex


###Putting it All Together
#code is complex but we will break it down into parts
#start by writing a function that cleans up strings so that all the feet
#and inches formats use the same x'y format when appropriate
attern <- "^([4-7])\\s*'\\s*(\\d+\\.?\\d*)$"

smallest <- 50
tallest <- 84
new_heights <- reported_heights %>% 
  mutate(original = height, 
         height = words_to_numbers(height) %>% convert_format()) %>%
  extract(height, c("feet", "inches"), regex = pattern, remove = FALSE) %>% 
  mutate_at(c("height", "feet", "inches"), as.numeric) %>%
  mutate(guess = 12*feet + inches) %>%
  mutate(height = case_when(
    !is.na(height) & between(height, smallest, tallest) ~ height, #inches 
    !is.na(height) & between(height/2.54, smallest, tallest) ~ height/2.54, #centimeters
    !is.na(height) & between(height*100/2.54, smallest, tallest) ~ height*100/2.54, #meters
    !is.na(guess) & inches < 12 & between(guess, smallest, tallest) ~ guess, #feet'inches
    TRUE ~ as.numeric(NA))) %>%
  select(-guess)
#check all the entries we converted
new_heights %>%
  filter(not_inches(original)) %>%
  select(original, height) %>% 
  arrange(height) %>%
  View()
#take a look at the shortest students in our dataset
new_heights %>% arrange(height) %>% head(n=7)


### String Splitting
#very common data wrangling operation is string splitting


















































































































































